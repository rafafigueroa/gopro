Introduction
Wireless communications system are notoriously easy to eavesdrop on. For instance, for home networks even the most advanced encryption techniques can be defeated with easily attainable tools [Vulnerabitlies].  And even when more robust encryption and security techniques are used, such as military applications, just the act of transmitting over radio waves can give valuable information to an attacker, such as the location of the transmitter [Wireless triangulation]
Therefore it is desirable to have a system which can be integrated into a wide range of platforms, allow secure laser based communications between two agents, and is low cost.

\background
The agents Marhes specializes in are small, autonomous, ground and air based mobile robots. The current systems include several Turtlebots from Clearpath Robotics, Octoroaches developed at UC Berkely, a “Panzer” unit developed in the Marhes lab, and several flying Quadcopters from AscTek Inc.





Of the four the Octoroach, in terms of power and loading, has the least capabilities while the Turtlebot has the most. The Quadrotor, while being in between the two in terms of loading and power, is the most maneuverable but is also the most unstable.  The system being developed must be capable of some form of operation on all four platforms.
\prototype
The platform being designed incorporates a Gimbel system designed and built in house. It uses inexpensive DC motors connected to an on-board processor. The (MCU?) processor can utilize USB or wireless cameras to perform computer vision tasks for the purpose of laser alignment and target acquisition. (one  or two sentences on multi robots in marhes here) In addition the laser system is connected in a modular fashion to allow the inclusion of both a laser and receiver for bidirectional communications, or just the receiver for a receive only mode. This gives an operational envelope, in terms of power requirements and weight, that will cover all four platforms present in the Marhes lab.
Methodology
Hardware
Gimbel System
The Gimbel System is composed of two DC motors on an aluminum frame. The top motor {figure blah} allows a full 360 degree rotation about the Z axis. The electronics housed in the Central unit consist of the Camera, the Laser, a photodiode receiver, a Signal Good LED, and a cluster of 4 LEDS used for identification. The side motor allows for a +/- 15 Degree rotation about the X axis. 
The motors are Polulu Micro Metal DC motors with a gear ration of 150:1. They are driven by a Polulu Junior blah dual DC motor driver. The driver is controlled through a serial port using the standard Polulu command set {appendix blah}. It is capable of delivering 2.5A of continuous current at voltages from 5V up to 24V. They are operated at 12V for improved torque. 
Laser and Receiver
The current laser operates in the 450 nM wavelength and is a standard laser pointer type. It is powered from 5 volts DC through transistor J? {Figure blah}. Since it is always active in the current design it provides a means of visible confirmation during testing. 
The photodiode was selected to match the wavelength of the laser. When the laser strikes the photodiode current flows through it and into the input of the OpAmp J blah at pin blah {figure}. If sufficient current is allowed to pass through to drive the voltage at the pin above the negative input then opamp output will be pulled high. The threshold voltage is selectable by adjusting the pot P1. 
The Signal Good indicator, LED 1, is tied to the output pin {blah} of J?. Once the output pin blah goes high in response to the photodiode pin going above the noise threshold the opamp allows current to flow through the LED to ground.
The output from the opamp currently goes directly to the CPU. The voltage level is selectable by the pullup voltage at the output pin. In the future this may be tied to a PPM or other type of modulation circuitry if desired. 
CPU (MCU?)
The CPU being used is an Intel Edison module. The Edison platform has a dual core 500 MHz atom processor, 1 GB of on board memory, and 4 GB of storage. In addition it includes WiFi, Bluetooth, a USB port for power and to provide a console port, and a USB OTG port. 
Camera
The current camera being used for development is a GoPro Hero3+. It is a Wifi camera capable of full HDMI resolution with a 90 FOV. 
Software
Algorithm
The algorithm under design needs to accomplish several tasks. It must identify a target in the image returned by the camera. It must be able to align the target to the center of the image. And it must then be able to align the laser with the receiver on the target. The algorithm developed allows the hosting agent to command the Laser Communications Module to align the laser onto the targets receiver and send a message over the link.
Results
System Configuration
Linux 3.2 OS
The Edison operates on a Debian 3.2 Headless kernel built from the Yocto project. It includes special libraries from Intel to support access to the extra features of the platform, such as GPIO ports and ADC ports. 
Python Version Blah
Python is a scripting language developed by Blah in <year>. It is a very poplular scripting language that is portable and easy to use. Python <version> was used in this project. The following commands install Python and required Python libraries.
Git python
Git blah…
<screen shot?>
OpenCV 2.blah
OpenCV is a mature, robust, computer vision library available to the Open Source community. It implements some of the most advanced computer vision algorithms available. OpenCV 2.x was installed onto the Debian image directly from the apt repositories with the following command:
Sudo apt-get install opencvblahblah
GoProHero 
The Hero3+ camera is controlled by connecting to its Ad Hoc net\methodologywork on the camera itself. To interface to the camera an open source tool, GoProHero, was used. It is available on github and to install version <blah> the following commands were issued:

\methodology
Stage 1 Thresholding
Target Identification with Thresholding
Thresholding is the simplest way to track an object. It works in scenarios where the relative brightness of an object is unique in the scene. The LEDs used for identification where purposely selected to allow for just this case. OpenCV is used to perform a thresholding operation, masking out all other areas of the image whose brightness is less than the thresholded value. Once this is done then the openCV command <blah> is used to find connected regions. Since only the LEDs should be left in the image it should also be the only regions identified. The number of regions identified is the target ID. Since 4 LEDs are used for identification, but 2 are needed to be active for centering of the image, a total of 3 targets can be identified using this method.
<Images and Masks>
Target Centering
The centroid of the identified region is found by using <blah command>. Based on the ID of the target, the center of these regions is calculated and subtracted from the center of the image. An additional offset is applied, to allow for calibration of the laser and detector positions. This offset is fed into the motor control laws and the process is repeated until the image is centered.
<image of centroid and line to center of image>
<code snippet>
Laser Alignment
Centering of the target will move the laser close to the photodetector but will probably not strike close enough to activate it. Therefor a Laser Alignment stage is necessary. At this stage the Signal Good LED will be searched for. It should be above the ID LEDs and will also be detectable with thresholding. If the LED is not illuminated then a small random offset will be applied to the center of the image. Once the Gimbal has moved the image to the new target center the LED is checked again. This process is repeated until the LED turns on.  At this point the message is sent across the laser to the target.
<Images of Signal Good and Mask>



